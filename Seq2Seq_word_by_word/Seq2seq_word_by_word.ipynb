{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2seq_word_by_word.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6KpqRUuE9ddBJceP38BYk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jRicciL/Aprendizaje_profundo_tareas_CICESE/blob/master/Seq2seq_word_by_word.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgqSMBonHZm_"
      },
      "source": [
        "# Seq2Seq a nivel palabra\n",
        "## Traductor de oraciones Inglés-Español\n",
        "### **Tarea 5:** Aprendizaje Profundo - CICESE\n",
        "\n",
        "> **Estudiante:** [Joel Ricci López](https://github.com/jRicciL), 2021\n",
        "\n",
        "***\n",
        "\n",
        "#### Descripción:\n",
        "Implementar un traductor Seq2Seq a nivel palabras para traducir oraciones del inglés al español.\n",
        "\n",
        "## Estrategia de solución:\n",
        "### Primera implementación:\n",
        "- Se usará la base de datos de frases inglés-español disponible en la web ManyThings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgIxtbUIWr01"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrGVahEZIkGc"
      },
      "source": [
        "### Descarga de los datos\n",
        "\n",
        "Montamos Google drive para tener los datos  disponibles desde la cuenta de drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_vE0dEJsu4E",
        "outputId": "95e77cd2-5be6-4e28-b53d-5dcde8903fb3"
      },
      "source": [
        "from google.colab import drive\n",
        " \n",
        "drive.mount('/content/gdrive')\n",
        "root_path = '/content/gdrive/My Drive/kaggle/nlp'\n",
        "%cd $root_path"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/kaggle/nlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6VS5N9iIr2m"
      },
      "source": [
        "Ahora procedemos a descargar y leer los datos:\n",
        "\n",
        "\n",
        "- Para la descarga de la base de datos se implementó el siguiente código:\n",
        "\n",
        "```python\n",
        "# Descarga de los datos\n",
        "!wget http://www.manythings.org/anki/spa-eng.zip\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\n",
        "    f'{root_path}/spa-eng.zip', 'r') as zf:\n",
        "    zf.extractall(root_path)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4RcSsrXI7NR"
      },
      "source": [
        "#### Lectura de los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du9VZVPptB_e",
        "outputId": "feb7b5fe-456f-4f1f-a153-c0c309b96e18"
      },
      "source": [
        "data_path = 'spa.txt'\n",
        "\n",
        "with open(data_path, 'r', encoding = 'utf-8') as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "print(40*'-', \n",
        "      f'\\nTotal de pares de oraciones: {len(lines)}\\n',\n",
        "      40*'-')\n",
        "\n",
        "# Mostramos algunas de las frases\n",
        "lines[10000:10005]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------- \n",
            "Total de pares de oraciones: 128084\n",
            " ----------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The air is damp.\\tEl aire está húmedo.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1743488 (Spamster) & #1905890 (hayastan)\\n',\n",
              " 'The box is here.\\tLa caja está aquí.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #9517311 (CK) & #9667671 (Shishir)\\n',\n",
              " 'The boy is kind.\\tEl niño es amable.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #46327 (CK) & #758526 (Shishir)\\n',\n",
              " 'The boy is nice.\\tEl niño es amable.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1414376 (enteka) & #758526 (Shishir)\\n',\n",
              " 'The bus is slow.\\tEl autobús es lento.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2002516 (bichodebola) & #2002666 (bichodebola)\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoBDOAhMtvaw"
      },
      "source": [
        "## Preparación de los datos\n",
        "### Vectorización de las oraciones\n",
        "Comenzamos con la fase de procesamiento de los textos. Se obtendrán los siguientes objetos:\n",
        "\n",
        "1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ13SFYfxt8Q",
        "outputId": "6f288779-63e8-4ae9-ad35-1696885c4901"
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOq0h55OtXyZ"
      },
      "source": [
        "num_samples = 10000 # Tamaño de la muestra para entrenamiento\n",
        "start_sample = 0\n",
        "\n",
        "# Realizamos un muestreo aleatorio de las frases\n",
        "# para obtenerl las num_samples muestras deseadas\n",
        "# lines_s = np.random.choice(a = lines, \n",
        "#                            size = num_samples, \n",
        "#                            replace = False)\n",
        "lines_s = lines[start_sample: \n",
        "                start_sample + num_samples]\n",
        "\n",
        "# Inicializamos las listas y sets de los \n",
        "# textos de entrada y salida\n",
        "# English texts\n",
        "input_texts      = []\n",
        "input_tokenized  = []\n",
        "# Spanish texts\n",
        "target_texts     = []\n",
        "target_tokenized = []\n",
        "# Conjunto de tokens\n",
        "input_tokens_set  = set() \n",
        "target_tokens_set = set()\n",
        "\n",
        "\n",
        "\n",
        "def tokenize_spanish(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  tokens = [token[1:]\n",
        "            if token[0] in (\"¿\",\"¡\") \n",
        "            else token\n",
        "            for token in tokens]\n",
        "  return tokens\n",
        "\n",
        "for line in lines_s:\n",
        "  # Separa los textos en los lenguajes correspondientes\n",
        "  input_text, target_text, _ = line.split('\\t')\n",
        "  # Lowercase\n",
        "  input_text, target_text = input_text.lower(), target_text.lower()\n",
        "  # Delimita los textos target con los siguientes tokens\n",
        "  target_text = 'START ' + target_text + ' END'\n",
        "\n",
        "  # Agrega a las listas correspondientes\n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target_text)\n",
        "\n",
        "  # Realizamos la fase de tokenización de los textos\n",
        "  in_tokens  = word_tokenize(input_text)\n",
        "  input_tokenized.append(in_tokens)\n",
        "\n",
        "  tar_tokens = tokenize_spanish(target_text)\n",
        "  target_tokenized.append(tar_tokens)\n",
        "\n",
        "  # Adicionalmente, añadimos los tokens nuevos al\n",
        "  # conjunto de tokens correspondiente\n",
        "  for token in in_tokens:\n",
        "    input_tokens_set.add(token)\n",
        "  \n",
        "  for token in tar_tokens:\n",
        "    target_tokens_set.add(token)\n",
        "  "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyTH8D5Vy3UT"
      },
      "source": [
        "### Exploramos un poco los conjuntos de caracteres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzKo86mJxL0L",
        "outputId": "a4ea50bd-1077-4d4e-f2a8-2a5115f634af"
      },
      "source": [
        "# Número de tokens en cada conjunto\n",
        "num_encoder_tokens = len(input_tokens_set)\n",
        "num_decoder_tokens = len(target_tokens_set)\n",
        "\n",
        "print('Número de tokens inglés: ', num_encoder_tokens)\n",
        "print('Número de tokens español:', num_decoder_tokens)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número de tokens inglés:  2603\n",
            "Número de tokens español: 4481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7GMMGupx9hf",
        "outputId": "8304fb90-1ec9-420b-8220-3f6ca93c896e"
      },
      "source": [
        "# Muestra de algunos de los tokens\n",
        "print('Tokens que conforman las sentencias de entrada:\\n',\n",
        "      f'{list(input_tokens_set)[:5]}\\n')\n",
        "      \n",
        "print('Tokens que conforman las sentencias objetivo:\\n',\n",
        "      f'{list(target_tokens_set)[:5]}')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokens que conforman las sentencias de entrada:\n",
            " ['crook', 'sweat', 'crying', 'thinks', 'idiots']\n",
            "\n",
            "Tokens que conforman las sentencias objetivo:\n",
            " ['pronto', 'defraudes', 'contamos', 'compré', 'amantes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSOwEqOA1RSg",
        "outputId": "38cd6b5a-1397-41cc-fe6a-9dce3a297df5"
      },
      "source": [
        "# Longitudes máximas, en tokens de cada conjunto\n",
        "max_encoder_seq_len = max(list(map(len, input_tokenized)))\n",
        "max_decoder_seq_len = max(list(map(len, target_tokenized)))\n",
        "\n",
        "print(f'Longitud maxima de oración en el idioma fuente:', \n",
        "      max_encoder_seq_len)\n",
        "print(f'Longitud maxima de oración en el idioma destino:', \n",
        "      max_decoder_seq_len)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longitud maxima de oración en el idioma fuente: 7\n",
            "Longitud maxima de oración en el idioma destino: 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIRCDvld17Jn"
      },
      "source": [
        "### Realizamos los diccionarios de tokens\n",
        "#### One-hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j28fRbkC2ldy"
      },
      "source": [
        "input_token_index  = dict([(token, i) \n",
        "                      for i, token in \n",
        "                      enumerate(input_tokens_set)])\n",
        "target_token_index = dict([(token, i) \n",
        "                      for i, token in \n",
        "                      enumerate(target_tokens_set)])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eekObNAuCi8b",
        "outputId": "0d5d49e3-fafd-4eb1-ff25-405c0402ca19"
      },
      "source": [
        "# Matrices vacias con las dimensiones correspondientes\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_tokenized),    # tamanio muestra = num de observaciones\n",
        "     max_encoder_seq_len, # numero de caracteres maximo por obs.\n",
        "     num_encoder_tokens   # indice de la secuencia\n",
        "    ), dtype = 'float32'\n",
        ")\n",
        "\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(target_tokenized),\n",
        "     max_decoder_seq_len,\n",
        "     num_decoder_tokens\n",
        "    ), dtype = 'float32'\n",
        ")\n",
        "\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(target_tokenized),\n",
        "     max_decoder_seq_len,\n",
        "     num_decoder_tokens\n",
        "    ), dtype = 'float32'\n",
        ")\n",
        "\n",
        "print(encoder_input_data.shape)\n",
        "print(decoder_input_data.shape)\n",
        "print(decoder_target_data.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 7, 2603)\n",
            "(8000, 12, 4481)\n",
            "(8000, 12, 4481)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSIeS0lkD-u6"
      },
      "source": [
        "for i, (in_tokens, tar_tokens) in \\\n",
        "    enumerate(zip(input_tokenized, target_tokenized)):\n",
        "\n",
        "    # codificacion de la secuencia de entrada\n",
        "    for t, token in enumerate(in_tokens):\n",
        "      encoder_input_data[i, t, input_token_index[token]]  = 1\n",
        "    # Rellenamos el resto con puntos\n",
        "    encoder_input_data[i, t + 1:, \n",
        "            input_token_index['.']] = 1\n",
        "\n",
        "    # codificacion de la secuencia de salida\n",
        "    for t, token in enumerate(tar_tokens):\n",
        "      decoder_input_data[i, t, target_token_index[token]] = 1\n",
        "      if t > 0:\n",
        "        # Recordar que al texto target se le agreg'o\n",
        "        # un inicio \\t y un final \\n\n",
        "        decoder_target_data[i, t - 1, \n",
        "                  target_token_index[token]] = 1\n",
        "    # Rellenamos el resto con espacios\n",
        "    decoder_input_data[i, t + 1:, target_token_index['.']] = 1\n",
        "    decoder_target_data[i, t:, target_token_index['.']]    = 1"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOUCu1RJEWR9"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "_9JJKsQ6vlq1",
        "outputId": "f7b5eb5a-5024-4be9-89d4-a8b09b42251c"
      },
      "source": [
        "plt.figure(figsize=(10, 3))\n",
        "plt.plot(decoder_input_data[-1][1], '.r')\n",
        "plt.plot(decoder_target_data[-1][0], 'b')\n",
        "plt.title('Primer palabra de secuencias normal y adelantada')\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "_AccSvsBxEbT",
        "outputId": "e78d1181-ebc3-4dc8-b07e-9a65bc25a34e"
      },
      "source": [
        "import pandas as pd\n",
        "idx = np.argmax(list(map(len, input_tokenized)))\n",
        "pd.DataFrame({\n",
        "    'Text': input_tokenized[idx],\n",
        "    'Vector': encoder_input_data[idx,:,input_token_index['he']],\n",
        "    }\n",
        ").T"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Text</th>\n",
              "      <td>``</td>\n",
              "      <td>look</td>\n",
              "      <td>,</td>\n",
              "      <td>''</td>\n",
              "      <td>she</td>\n",
              "      <td>said</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vector</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0     1  2   3    4     5  6\n",
              "Text    ``  look  ,  ''  she  said  .\n",
              "Vector   0     0  0   0    0     0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6_BJsSixd1Z"
      },
      "source": [
        "# Modelo seq2seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v4AKiCSx6VC"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy_riTKbMdci"
      },
      "source": [
        "batch_size = 64\n",
        "epochs     = 20\n",
        "latent_dim = 1024"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkiyFZFfQwW0"
      },
      "source": [
        "### Codificador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td83Jz2QQyIj",
        "outputId": "cb0935fe-fea0-4cb5-9465-0d0730ef4bba"
      },
      "source": [
        "encoder_inputs = Input(shape = (None, num_encoder_tokens))\n",
        "\n",
        "encoder_o, encoder_h, encoder_c = LSTM(\n",
        "    units        = latent_dim,\n",
        "    return_state = True\n",
        ")(encoder_inputs)\n",
        "\n",
        "encoder_states = [encoder_h, encoder_c]\n",
        "\n",
        "print(encoder_inputs.shape)\n",
        "print(encoder_o.shape, encoder_h.shape, encoder_c.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, 2603)\n",
            "(None, 1024) (None, 1024) (None, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82x5OJBLRUrv"
      },
      "source": [
        "### Decodificador\n",
        "\n",
        "1. Para el decodificador usaremos de nuevo una LSTM\n",
        "2. La entrada del decodificador es la salida del codificador\n",
        "3. El estado inicial (de la primera etapa) del decodificador estara dado por los estados internos del decodificador.\n",
        "4. Usaremos el estado interno de la 'ultima etapa del decodificador para la inferencia.\n",
        "5. Se agrega una capa densa a la salida para obtener la secuencia codificada \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHFzkJOXTPsF"
      },
      "source": [
        "decoder_inputs = Input(shape = (None, num_decoder_tokens))\n",
        "\n",
        "layer_lstm = LSTM(\n",
        "    units = latent_dim,\n",
        "    return_sequences = True,\n",
        "    return_state = True\n",
        ")\n",
        "\n",
        "decoder_O, _, _ = layer_lstm(\n",
        "    decoder_inputs,\n",
        "    initial_state = encoder_states\n",
        ")\n",
        "\n",
        "layer_dense = Dense(\n",
        "    units = num_decoder_tokens,\n",
        "    activation = 'softmax'\n",
        ")\n",
        "\n",
        "decoder_outputs = layer_dense(decoder_O)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LlNeaa2UER3"
      },
      "source": [
        "## Modelo Seq2seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7jGbxBrULaW",
        "outputId": "cfd6a594-d874-4178-c463-e38d92c691f0"
      },
      "source": [
        "model = Model(\n",
        "    inputs = [encoder_inputs, decoder_inputs],\n",
        "    outputs = decoder_outputs\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 2603)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 4481)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 1024), (None 14860288    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 1024), 22552576    input_2[0][0]                    \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 4481)   4593025     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 42,005,889\n",
            "Trainable params: 42,005,889\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qmv2ciDUUp0"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = 'rmsprop',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJqqCzTgUcyr"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint \n",
        "from tensorflow.keras.callbacks import TensorBoard "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH3rDHRbUoji"
      },
      "source": [
        "my_callbacks = [\n",
        "    EarlyStopping(patience = 5),\n",
        "    #ModelCheckpoint(filepath = 's2s_words_MT.{epoch:04d}-{val_loss:.2f}.h5'),\n",
        "    TensorBoard(log_dir = './logs_MT_words')\n",
        "]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3voCs5jmVmwy",
        "outputId": "0943e8fd-172c-4f41-fec7-99bd74ffee89"
      },
      "source": [
        "history = model.fit(\n",
        "    x = [encoder_input_data, decoder_input_data],\n",
        "    y = decoder_target_data,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    shuffle = True,\n",
        "    validation_split = 0.2,\n",
        "    callbacks = my_callbacks\n",
        ")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - 43s 105ms/step - loss: 3.1487 - accuracy: 0.5686 - val_loss: 2.3480 - val_accuracy: 0.6220\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 2.0357 - accuracy: 0.6662 - val_loss: 2.0763 - val_accuracy: 0.7059\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.7123 - accuracy: 0.7354 - val_loss: 1.8262 - val_accuracy: 0.7425\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4842 - accuracy: 0.7619 - val_loss: 1.7464 - val_accuracy: 0.7536\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3673 - accuracy: 0.7727 - val_loss: 1.6795 - val_accuracy: 0.7617\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.2436 - accuracy: 0.7848 - val_loss: 1.6735 - val_accuracy: 0.7650\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.1181 - accuracy: 0.7981 - val_loss: 1.6277 - val_accuracy: 0.7711\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.0177 - accuracy: 0.8096 - val_loss: 1.6376 - val_accuracy: 0.7717\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.9192 - accuracy: 0.8204 - val_loss: 1.6360 - val_accuracy: 0.7757\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8356 - accuracy: 0.8297 - val_loss: 1.6102 - val_accuracy: 0.7754\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7688 - accuracy: 0.8387 - val_loss: 1.6203 - val_accuracy: 0.7770\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6861 - accuracy: 0.8525 - val_loss: 1.6286 - val_accuracy: 0.7772\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6204 - accuracy: 0.8625 - val_loss: 1.6055 - val_accuracy: 0.7777\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5657 - accuracy: 0.8700 - val_loss: 1.6388 - val_accuracy: 0.7794\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5150 - accuracy: 0.8801 - val_loss: 1.6254 - val_accuracy: 0.7779\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4616 - accuracy: 0.8920 - val_loss: 1.6281 - val_accuracy: 0.7794\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4127 - accuracy: 0.9017 - val_loss: 1.6223 - val_accuracy: 0.7803\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3830 - accuracy: 0.9087 - val_loss: 1.6703 - val_accuracy: 0.7792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I32d0QKcaANA"
      },
      "source": [
        "# Guarda el modelo\n",
        "model.save(f\"{root_path}/modelo_seq2seq_TRAINED.h5\")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8pete43WG0C"
      },
      "source": [
        "## Inferencia en Seq2Seq\n",
        "\n",
        "1. El codificador permanece sin cambios\n",
        "2. El decodificador:\n",
        "  - Transformar la información semántica en forma completa por el codificador y luego pasar los estados ocultos de salida al decodificador para que los decodifique palabra por palabra generando así la nueva secuencia.\n",
        "  - Se usarán los estados que resultan de la red LSTM, pues se usarán para pasar de un caracter al siguiente.\n",
        "  - El decodificador tiene como estado inicial los estados de salida del codificador.\n",
        "  - La entrada al decodificador será el anterior caracter predicho por el mismo, inicializando con la palabra START"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EhFyV-pa5dG"
      },
      "source": [
        "# Codificador\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Entradas de decodificador\n",
        "decoder_state_input_h = Input(shape = (latent_dim,))\n",
        "decoder_state_input_c = Input(shape = (latent_dim,))\n",
        "# Combinados\n",
        "decoder_states_inputs = [decoder_state_input_h, \n",
        "                         decoder_state_input_c]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5k1nCTucJoG"
      },
      "source": [
        "Ahora usaremos las capas `layer_lstm` y `layer_dense`, que han sido entrenadas previamente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_ityKN6cV-e"
      },
      "source": [
        "decoder_O, state_H, state_C = layer_lstm(\n",
        "  decoder_inputs,\n",
        "  initial_state = decoder_states_inputs    \n",
        ")\n",
        "\n",
        "decoder_outputs = layer_dense(decoder_O)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNcHzQvkcskH"
      },
      "source": [
        "decoder_model = Model(\n",
        "    inputs = [decoder_inputs] + decoder_states_inputs,\n",
        "    outputs = [decoder_outputs] + [state_H, state_C]\n",
        ")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK3-Kfpmc5LL"
      },
      "source": [
        "# Diccionarios invertidos caracter-indice a indice-caracter\n",
        "# para decodificar\n",
        "reverse_input_token_index = {\n",
        "    idx: token for token, idx in input_token_index.items()\n",
        "}\n",
        "\n",
        "reverse_target_token_index = {\n",
        "    idx: token for token, idx in target_token_index.items()\n",
        "}\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jojzxyfIdcab"
      },
      "source": [
        "# Función para decodificar la secuencia de entrada en \n",
        "def decode_sequence(input_seq):\n",
        "\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "  target_seq[0, 0, target_token_index['START']] = 1\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "\n",
        "  while not stop_condition:\n",
        "    output_token, state_H, state_C = decoder_model.predict(\n",
        "        [target_seq] + states_value\n",
        "    )\n",
        "\n",
        "    sampled_token_index = np.argmax(output_token[0, -1, :])\n",
        "    sampled_token = reverse_target_token_index[sampled_token_index]\n",
        "    decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "    # Fin del procesamiento de la secuencia\n",
        "    if (sampled_token == 'END' or len(decoded_sentence) >\n",
        "        max_decoder_seq_len):\n",
        "      stop_condition = True\n",
        "    \n",
        "    # Actualiza la entrada del decodificador para la\n",
        "    # siguiente prediccion\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, sampled_token_index] = 1\n",
        "\n",
        "    # Actualiza los estados\n",
        "    states_value = [state_H, state_C]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tgW7n49aFIz",
        "outputId": "5d07c639-223b-4387-b1ec-08c943208727"
      },
      "source": [
        "seq_index = 1000\n",
        "input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print(input_texts[seq_index], ' --> ', decoded_sentence)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "atlantis is real.  -->   la atlántida\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH1kYnupuWfO",
        "outputId": "8f4f0fce-9a9d-4dc6-f997-79578b81cdee"
      },
      "source": [
        "print('Oracion en ingles --> traduccion por la red seq2seq al espaniol')\n",
        "\n",
        "for seq_index in range(2000, 2050):\n",
        "  # Secuencia codificada en one-hot\n",
        "  input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "  print(input_texts[seq_index], ' --> ', decoded_sentence)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Oracion en ingles --> traduccion por la red seq2seq al espaniol\n",
            "i think i got it.  -->   creo que tengo\n",
            "i think it works.  -->   creo que funciona\n",
            "i think it's tom.  -->   creo que es verdad\n",
            "i told tom to go.  -->   le dije a tom\n",
            "i told tom to go.  -->   le dije a tom\n",
            "i told the truth.  -->   dije la verdad\n",
            "i totally forgot.  -->   me olvidé totalmente\n",
            "i totally get it.  -->   yo totalmente\n",
            "i truly doubt it.  -->   de verdad lo\n",
            "i understand tom.  -->   lo comprendo\n",
            "i understand now.  -->   ahora lo entiendo\n",
            "i understand why.  -->   comprendo el\n",
            "i understand why.  -->   comprendo el\n",
            "i understand why.  -->   comprendo el\n",
            "i understand why.  -->   comprendo el\n",
            "i understand you.  -->   lo entiendo .\n",
            "i used to be fat.  -->   solía ser gordo\n",
            "i visited boston.  -->   visité boston\n",
            "i waited for you.  -->   te estuve esperando\n",
            "i waited for you.  -->   te estuve esperando\n",
            "i walk every day.  -->   me todos todos\n",
            "i want mary back.  -->   quiero que vuelva\n",
            "i want mary back.  -->   quiero que vuelva\n",
            "i want tom fired.  -->   quiero que despidan\n",
            "i want a divorce.  -->   quiero un ordenador\n",
            "i want a divorce.  -->   quiero un ordenador\n",
            "i want a hot dog.  -->   quiero un nuevo\n",
            "i want a martini.  -->   quiero un ordenador\n",
            "i want a new car.  -->   quiero un coche\n",
            "i want my lawyer.  -->   quiero a mi abogado\n",
            "i want my mother.  -->   quiero a mi abogado\n",
            "i want some food.  -->   quiero un poco\n",
            "i want some milk.  -->   quiero un poco\n",
            "i want some more.  -->   quiero un poco\n",
            "i want that book.  -->   quiero ese libro\n",
            "i want to eat it.  -->   quiero verlo\n",
            "i want to eat it.  -->   quiero verlo\n",
            "i want to go out.  -->   quiero ir a casa\n",
            "i want to retire.  -->   quiero creer\n",
            "i want to see it.  -->   quiero verlo\n",
            "i want to try it.  -->   quiero verlo\n",
            "i want you to go.  -->   quiero que tú\n",
            "i want your love.  -->   quiero tu amor\n",
            "i was 13 in 2003.  -->   yo tenía esta\n",
            "i was a rich man.  -->   yo era un hombre\n",
            "i was astonished.  -->   me quedé pasmado\n",
            "i was born there.  -->   yo nací allí\n",
            "i was dumbstruck.  -->   me quedé sin\n",
            "i was dumbstruck.  -->   me quedé sin\n",
            "i was happy then.  -->   yo estaba feliz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gr6bVbbe5mO"
      },
      "source": [
        "# Referencias\n",
        "\n",
        "1. Mariano Rivera (2018). **[Seq2Seq : Modelos de redes recurrentes para transformar secuencias a secuencias](http://personal.cimat.mx:8181/~mrivera/cursos/aprendizaje_profundo/seq2seq/seq2seq.html)**. *Consultado el 18 de marzo del 2021.*"
      ]
    }
  ]
}